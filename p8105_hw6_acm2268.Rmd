---
title: "p8105_hw6_acm2268"
author: "Amanda Miles"
date: "12/4/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)

```

# Question 1: Birthweight

## Data Import

```{r q1_import}

birthweight_df = read_csv(file = "./data/birthweight.csv") %>%
  janitor::clean_names() %>%
  view()

str(birthweight_df)
skimr::skim(birthweight_df)

```

The dataset includes information on 4,342 children. It includes 20  variables and has 4,342 rows. All of the variables are numeric and there are no missing values. 

## Data Cleaning

```{r q1_cleaning}

birthweight_clean = birthweight_df %>%
  mutate(
    babysex = as.factor(as.character(babysex)),
    babysex = fct_recode(babysex, 
                     "female" = "2",
                     "male" = "1"),
    frace = as.factor(as.character(frace)),
    frace = fct_recode(frace,
                       "White" = "1",
                       "Black" = "2",
                       "Asian" = "3",
                       "Puerto Rican" = "4",
                       "Other" = "8",
                       "Unknown" = "9"),
    malform = as.factor(as.character(malform)),
    malform = fct_recode(malform,
                         "absent" = "0",
                         "present" = "1"),
    mrace = as.factor(as.character(mrace)),
    mrace = fct_recode(mrace,
                       "White" = "1",
                       "Black" = "2",
                       "Asian" = "3",
                       "Puerto Rican" = "4",
                       "Other" = "8")
    )

birthweight_clean %>%
  summarize(
    frace_unknown = sum(frace == "Unknown"),
    mrace_other = sum(mrace == "Other")
  )

```

Converted the appropriate variables to factors and investigated the unknown levels in frace = "unknown" and mrace = "other".

## Model 1: Regression Model for Birthweight

```{r q1_model_1}

model_1 = lm(bwt ~ gaweeks + momage + smoken + fincome, data = birthweight_clean)

model_1 %>% 
  broom::tidy() %>%
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

```

The predictor variables were chosen based on my hypothesized structure for the factors that underlie birth weight. Premature birth can lead to a lower birth weight, so I hypothesize that the number of gestation weeks at birth is a factor that drives baby birth weight. Additionally, mothers who are older when they give birth or are smokers can have lower birth weight babies, so I hypothesize that mother's age and mother's smoking status are two additional factors that underlie baby's birth weight. Additionally, I hypothesize that SES could be associated with baby's birth weight so I included family's monthly income as the last predictor in my model. My proposed linear regression model for birth weight is as follows: 

bwt = b0 + b1(gaweeks) + b2(momage) + b3(smoken) + b4(fincome) 

## Residual Plot for Model 1

```{r q1_residuals}

birthweight_res = birthweight_clean %>%
  add_residuals(model_1) %>%
  add_predictions(model_1) %>% 
  mutate(
    resid = round(resid, digits = 3),
    pred = round(pred, digits = 3)
  )

ggplot(birthweight_res, aes(x = pred, y = resid)) + 
  geom_point(size = .5, color = "blue") +
  labs(x = "Predicted Birthweight (grams)",
       y = "Residual",
       title = "Association between Residuals and Predicted Birthweight")

```

## Cross-Validation

### Created Models 2 and 3

```{r q1_other_models}

model_2 = lm(bwt ~ blength + gaweeks, data = birthweight_clean)

model_3 = lm(bwt ~ 
               bhead + blength + babysex + 
               bhead * blength + bhead * babysex + blength * babysex +
               bhead * blength * babysex,
               data = birthweight_clean)

```

### Creating Crossv_mc Tibble with Train & Test Data

```{r q1_crossv}

cv_df = 
  crossv_mc(birthweight_clean, 100)

cv_df = cv_df %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>% view()

```

### Fit models and get RMSEs (Root Mean Squared Errors)

```{r q1_model_rmses}

rmse_df =
  cv_df %>%
  mutate(
    model_1 = map(.x = train, 
                  ~lm(bwt ~ gaweeks + momage + smoken + fincome, 
                  data = .x)),
    model_2 = map(.x = train,
                  ~lm(bwt ~ blength + gaweeks, 
                      data = .x)),
    model_3 = map(.x = train,
                  ~lm(bwt ~ 
                      bhead + blength + babysex + 
                      bhead * blength + bhead * babysex +
                      blength * babysex +
                      bhead * blength * babysex,
                      data = .x))
  ) %>%
  mutate(
     rmse_model_1 = map2_dbl(model_1, 
                             test, 
                             ~rmse(model = .x, data = .y)),
    rmse_model_2 = map2_dbl(model_2,
                            test, 
                            ~rmse(model = .x, data = .y)),
    rmse_model_3 = map2_dbl(model_3,
                            test, 
                            ~rmse(model = .x, data = .y))
  )


```

### Model Choice

```{r q1_model_choice}

rmse_clean = rmse_df %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) 

ggplot(rmse_clean, aes(x = model, y = rmse, color = model)) +
  geom_violin() +
  theme(legend.position = "right") +
  labs(x = "Regression Model",
       y = "RMSE",
       title = "RMSEs by Birthweight Regression Model")

rmse_clean %>%
  group_by(model) %>%
  summarize(avg_rmse = mean(rmse))
 

```
Based on the average RMSE for each of the models, Model 1 has the highest average RMSE, Model 2 has the second highest average RMSE, and Model 3 has the lowest average RMSE. From the Violin plot, we can see that Model 1 consistently has the highest RMSE when fitted to the test data sets. While there is some overlap in the RMSEs for Model 2 and Model 3, Model 2 generally has a higher RMSE than Model 3. 

RMSE gives us a sense of the average distance between the birth weight that is observed and the birth weight values predicted by each of the regression models. Since Model 3 has the lowest average RMSE, Model 3 is generally the best of the three models for predicting baby's birth weight. 

In other words, a model which includes the main effects and interactions between the baby's head circumference at birth, the baby's length in centimeters at birth, and the baby's sex more accurately predicts baby's birth weight when compared to a model that includes the main effects of the baby's gestational age in weeks, the mother's age at birth, the mother's smoking status, and the family's financial income or a model that includes the main effects of the baby's length at birth and the baby's gestational age in weeks.

# Question 2: Central Park Weather in 2017

## Data Import

```{r q2_data_import}

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

view(weather_df)

set.seed(1)

```

## Sample 5,000 Bootstraps and Run Model on Each

```{r}

 weather_boots = weather_df %>% 
  bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    glance = map(models, broom::glance)
  )

log_boots = 
  weather_boots %>%
  select(.id, strap, results) %>%
  unnest(results) %>%
  select(.id, strap, term, estimate, std.error)

r_2_boots = 
  weather_boots %>%
  select(.id, strap, glance) %>%
  unnest(glance) %>%
  select(.id, strap, r.squared)

```

## Calculating Log(B0*B1)

```{r q2_log_b0_b1}

log_boots_2 = 
  log_boots %>%
  mutate(
    log_estimate = log(estimate)
  ) %>%
  group_by(.id) %>%
  summarize(
    log_slope_int = sum(log_estimate)
    ) 

view(log_boots_2)

```

## Distribution Plots

```{r}

ggplot(r_2_boots, aes(x = r.squared)) + geom_density(color = "blue", fill = "lightcyan2") +
labs(x = "R-Squared",
     y = "Density",
     title = "Distribution of Bootstrap R-Squared Values")

ggplot(log_boots_2, aes(x = log_slope_int)) + geom_density(color = "seagreen4", fill = "darkseagreen2") +
labs(x = "Log(B0*B1)",
     y = "Density",
     title = "Distribution of Bootstrap Model Log(B0*B1)")


```
The plot of the 5,000 bootstrap model R-squared values is approximately normally distributed. The values range from approximately 0.87 to approximately 0.937, with the mean being approximately 0.91.

The plot of the 5,000 bootstrap model log(b0*b1) values is approximately normally distributed. The values range from approximately 1.92 to approximately 2.10, with the mean being approximately 2.01.  


## Confidence Intervals

```{r}

r_2_boots %>%
  summarize(
    lower_cl = quantile(r.squared, 0.025),
    upper_cl = quantile(r.squared, 0.975)
  )
 
log_boots_2 %>%
  summarize(
    lower_cl = quantile(log_slope_int, 0.025),
    upper_cl = quantile(log_slope_int, 0.975)
   )

```

The 95% confidence interval for the model R-squared  ranges from 0.8937 to 0.9271.

The 95% confidence interval for the model log(b0*b1) ranges from 1.9649 to 2.0589.


